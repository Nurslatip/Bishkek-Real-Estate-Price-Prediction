{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nurslatip/Bishkek-Real-Estate-Price-Prediction/blob/main/1st_comp_rf_catboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_naueh7bvWIQ",
        "outputId": "a68a8696-5ed6-4c0d-f30b-e12f0574fab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
            "  Downloading sqlalchemy-2.0.42-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
            "  Downloading greenlet-3.2.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sqlalchemy-2.0.42-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading greenlet-3.2.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (585 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.5/585.5 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: greenlet, colorlog, sqlalchemy, alembic, optuna\n",
            "Successfully installed alembic-1.16.4 colorlog-6.9.0 greenlet-3.2.3 optuna-4.4.0 sqlalchemy-2.0.42\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAA1jEKwlZH2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import re\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "sns.set(style=\"darkgrid\")\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, cross_val_predict, KFold\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.pruners import MedianPruner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwUAIGiJuhap"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U2sWbtqlziu"
      },
      "outputs": [],
      "source": [
        "train_file_path =\"/content/train.csv\"\n",
        "train = pd.read_csv(train_file_path)\n",
        "test_file_path = \"/content/test.csv\"\n",
        "test = pd.read_csv(test_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcLp_R2gMbhT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHx7UXiwup1e"
      },
      "outputs": [],
      "source": [
        "test_id_column = test.id\n",
        "cols_to_drop = [\n",
        "    'Телефон',\n",
        "    'Интернет',\n",
        "    'Мебель',\n",
        "    'Возможность рассрочки',\n",
        "    'Возможность обмена',\n",
        "    'Разное',\n",
        "    'Пол',\n",
        "    'Возможность ипотеки',\n",
        "    'Площадь участка',\n",
        "    'Канализация',\n",
        "    'Питьевая вода',\n",
        "    'Электричество',\n",
        "    'added',\n",
        "    'upped',\n",
        "    'view_count',\n",
        "    'hearts'\n",
        "]\n",
        "train.drop(columns=cols_to_drop, inplace=True)\n",
        "\n",
        "\n",
        "test.drop(columns=cols_to_drop, inplace=True)\n",
        "test.drop('id', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "train.insert(0, 'room_count', train['main'].str.extract(r'(\\d+)-комн'))\n",
        "train['room_count'] = train['room_count'].astype(float)\n",
        "\n",
        "\n",
        "test.insert(0, 'room_count', test['main'].str.extract(r'(\\d+)-комн'))\n",
        "test['room_count'] = test['room_count'].astype(float)\n",
        "\n",
        "\n",
        "train.loc[train.room_count.isna(), 'room_count'] = 7\n",
        "\n",
        "\n",
        "test.loc[test.room_count.isna(), 'room_count'] = 7\n",
        "\n",
        "\n",
        "train.drop(6674, axis=0, inplace=True)\n",
        "train.drop(2255, axis=0, inplace=True)\n",
        "\n",
        "\n",
        "train.insert(8, 'house_material', train['Дом'].str.extract(r'^(.*?)\\s*(?:,|$)'))\n",
        "train.insert(9, 'year_built', train['Дом'].str.extract(r'(\\d{4})').astype(float))\n",
        "\n",
        "test.insert(8, 'house_material', test['Дом'].str.extract(r'^(.*?)\\s*(?:,|$)'))\n",
        "test.insert(9, 'year_built', test['Дом'].str.extract(r'(\\d{4})').astype(float))\n",
        "\n",
        "\n",
        "def fill_year_built_by_series_mode(df, series_col='Серия', year_col='year_built'):\n",
        "    mode_years = df.groupby(series_col)[year_col].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
        "    global_mode = df[year_col].mode().iloc[0]\n",
        "\n",
        "    def fill_row(row):\n",
        "        if pd.isna(row[year_col]):\n",
        "            return mode_years.get(row[series_col], global_mode)\n",
        "        else:\n",
        "            return row[year_col]\n",
        "\n",
        "    df[year_col] = df.apply(fill_row, axis=1)\n",
        "    return df\n",
        "\n",
        "\n",
        "train = fill_year_built_by_series_mode(train)\n",
        "test = fill_year_built_by_series_mode(test)\n",
        "\n",
        "\n",
        "def add_is_new_building_feature(df, year_col='year_built', threshold_year=2025, insert_pos=10):\n",
        "    is_new = df[year_col] >= threshold_year\n",
        "    df['is_new_building'] = is_new.map({True: 'Yes', False: 'No'})\n",
        "    col = df.pop('is_new_building')\n",
        "    df.insert(insert_pos, 'is_new_building', col)\n",
        "    return df\n",
        "\n",
        "\n",
        "train = add_is_new_building_feature(train)\n",
        "test = add_is_new_building_feature(test)\n",
        "\n",
        "\n",
        "train.drop([5075, 5424], axis=0, inplace=True)\n",
        "\n",
        "\n",
        "def extract_floor(s):\n",
        "    if pd.isna(s):\n",
        "        return None\n",
        "    try:\n",
        "        floor_num = int(s.split()[0])\n",
        "        return floor_num\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "\n",
        "def extract_total_floors(s):\n",
        "    if pd.isna(s):\n",
        "        return None\n",
        "    try:\n",
        "        total = int(s.split()[-1])\n",
        "        return total\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "train.insert(12, 'floor', train['Этаж'].apply(extract_floor))\n",
        "train.insert(13, 'total_floors', train['Этаж'].apply(extract_total_floors))\n",
        "\n",
        "\n",
        "test.insert(12, 'floor', test['Этаж'].apply(extract_floor))\n",
        "test.insert(13, 'total_floors', test['Этаж'].apply(extract_total_floors))\n",
        "\n",
        "\n",
        "def process_basement_feature(df, floor_col='Этаж', insert_pos=14):\n",
        "    mask_basement = df[floor_col].str.contains(r'цоколь|подвал', case=False, na=False)\n",
        "\n",
        "    df['is_basement'] = 'No'\n",
        "    df.loc[mask_basement, 'is_basement'] = 'Yes'\n",
        "\n",
        "    df.loc[mask_basement, 'floor'] = 0\n",
        "\n",
        "    df.loc[mask_basement, 'total_floors'] = (\n",
        "        df.loc[mask_basement, floor_col]\n",
        "        .str.extract(r'из (\\d+)')\n",
        "        .iloc[:, 0]\n",
        "        .astype(float)\n",
        "    )\n",
        "\n",
        "    col = df.pop('is_basement')\n",
        "    df.insert(insert_pos, 'is_basement', col)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "train = process_basement_feature(train)\n",
        "test = process_basement_feature(test)\n",
        "\n",
        "\n",
        "train.drop(6824, axis=0, inplace=True)\n",
        "\n",
        "\n",
        "train.insert(16, 'total_area', (\n",
        "    train['Площадь']\n",
        "    .str.extract(r'^([\\d.]+)')\n",
        "    .iloc[:, 0]\n",
        "    .astype(float)\n",
        "))\n",
        "\n",
        "\n",
        "test.insert(16, 'total_area', (\n",
        "    test['Площадь']\n",
        "    .str.extract(r'^([\\d.]+)')\n",
        "    .iloc[:, 0]\n",
        "    .astype(float)\n",
        "))\n",
        "\n",
        "\n",
        "def add_missing_flag(df, col_name, insert_pos):\n",
        "    missing_flag = df[col_name].isna().map({True: 'Yes', False: 'No'})\n",
        "    df.insert(insert_pos, f'{col_name}_missing', missing_flag)\n",
        "    df[col_name] = df[col_name].fillna('не указано')\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAVqgwa7uugE"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "train = add_missing_flag(train, 'Отопление', 19)\n",
        "train = add_missing_flag(train, 'Состояние', 20)\n",
        "\n",
        "test = add_missing_flag(test, 'Отопление', 19)\n",
        "test = add_missing_flag(test, 'Состояние', 20)\n",
        "\n",
        "\n",
        "features_to_drop = [\n",
        "    'main',\n",
        "    'Дом',\n",
        "    'Этаж',\n",
        "    'Площадь',\n",
        "    'Газ',\n",
        "    'Санузел',\n",
        "    'Балкон',\n",
        "    'Входная дверь',\n",
        "    'Парковка',\n",
        "    'Высота потолков',\n",
        "    'Безопасность',\n",
        "    'Правоустанавливающие документы',\n",
        "    'address',\n",
        "    'is_new_building',\n",
        "    'is_basement',\n",
        "    'Отопление_missing',\n",
        "    'Состояние_missing',\n",
        "    'Тип предложения',\n",
        "    'year_built'\n",
        "]\n",
        "train.drop([6582, 3538, 1535], axis=0, inplace=True)\n",
        "\n",
        "\n",
        "train.drop(features_to_drop, axis=1, inplace=True)\n",
        "test.drop(features_to_drop, axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6lmXoHHu9ad"
      },
      "outputs": [],
      "source": [
        "y = train.usd_price\n",
        "train.drop('usd_price' , axis = 1 , inplace=True)\n",
        "X = train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLZjERjW0htq"
      },
      "outputs": [],
      "source": [
        "numeric_features = train.select_dtypes([np.number])\n",
        "categorical_features = train.dtypes[train.dtypes == \"object\"].index.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY7PsEWFu92v"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXH-FDhby6g_",
        "outputId": "a22dd936-4be1-4cba-9a4e-d96202a633c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-31 14:13:12,796] Using an existing study with name 'random_forest_hyperparameter_tuning' instead of creating a new one.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Optuna optimization for RandomForestRegressor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-31 14:13:28,302] Trial 2 finished with value: 0.8782732835020566 and parameters: {'rf_regressor__n_estimators': 218, 'rf_regressor__max_depth': 24, 'rf_regressor__min_samples_split': 15, 'rf_regressor__min_samples_leaf': 6, 'rf_regressor__max_features': 0.8}. Best is trial 2 with value: 0.8782732835020566.\n",
            "[I 2025-07-31 14:13:43,000] Trial 3 finished with value: 0.8489861659302265 and parameters: {'rf_regressor__n_estimators': 369, 'rf_regressor__max_depth': 5, 'rf_regressor__min_samples_split': 20, 'rf_regressor__min_samples_leaf': 9, 'rf_regressor__max_features': 1.0}. Best is trial 2 with value: 0.8782732835020566.\n",
            "[I 2025-07-31 14:13:58,645] Trial 4 finished with value: 0.881263275381596 and parameters: {'rf_regressor__n_estimators': 244, 'rf_regressor__max_depth': 11, 'rf_regressor__min_samples_split': 13, 'rf_regressor__min_samples_leaf': 2, 'rf_regressor__max_features': 0.8}. Best is trial 4 with value: 0.881263275381596.\n",
            "[I 2025-07-31 14:14:15,563] Trial 5 finished with value: 0.8785403808041174 and parameters: {'rf_regressor__n_estimators': 281, 'rf_regressor__max_depth': 17, 'rf_regressor__min_samples_split': 2, 'rf_regressor__min_samples_leaf': 7, 'rf_regressor__max_features': 0.8}. Best is trial 4 with value: 0.881263275381596.\n",
            "[I 2025-07-31 14:14:23,559] Trial 6 finished with value: 0.8691434322974767 and parameters: {'rf_regressor__n_estimators': 187, 'rf_regressor__max_depth': 7, 'rf_regressor__min_samples_split': 15, 'rf_regressor__min_samples_leaf': 5, 'rf_regressor__max_features': 0.8}. Best is trial 4 with value: 0.881263275381596.\n",
            "[I 2025-07-31 14:14:30,044] Trial 7 finished with value: 0.8028691817788755 and parameters: {'rf_regressor__n_estimators': 348, 'rf_regressor__max_depth': 11, 'rf_regressor__min_samples_split': 11, 'rf_regressor__min_samples_leaf': 6, 'rf_regressor__max_features': 'log2'}. Best is trial 4 with value: 0.881263275381596.\n",
            "[I 2025-07-31 14:15:03,180] Trial 8 finished with value: 0.8875246056110265 and parameters: {'rf_regressor__n_estimators': 319, 'rf_regressor__max_depth': 24, 'rf_regressor__min_samples_split': 3, 'rf_regressor__min_samples_leaf': 2, 'rf_regressor__max_features': 1.0}. Best is trial 8 with value: 0.8875246056110265.\n",
            "[I 2025-07-31 14:15:12,610] Trial 9 finished with value: 0.8812780842071077 and parameters: {'rf_regressor__n_estimators': 210, 'rf_regressor__max_depth': 10, 'rf_regressor__min_samples_split': 12, 'rf_regressor__min_samples_leaf': 2, 'rf_regressor__max_features': 0.6}. Best is trial 8 with value: 0.8875246056110265.\n",
            "[I 2025-07-31 14:15:17,409] Trial 10 finished with value: 0.8738856327778143 and parameters: {'rf_regressor__n_estimators': 52, 'rf_regressor__max_depth': 22, 'rf_regressor__min_samples_split': 15, 'rf_regressor__min_samples_leaf': 8, 'rf_regressor__max_features': 1.0}. Best is trial 8 with value: 0.8875246056110265.\n",
            "[I 2025-07-31 14:15:37,083] Trial 11 finished with value: 0.8836969853028754 and parameters: {'rf_regressor__n_estimators': 331, 'rf_regressor__max_depth': 11, 'rf_regressor__min_samples_split': 3, 'rf_regressor__min_samples_leaf': 4, 'rf_regressor__max_features': 0.8}. Best is trial 8 with value: 0.8875246056110265.\n",
            "[I 2025-07-31 14:15:51,236] Trial 12 finished with value: 0.8718149744073551 and parameters: {'rf_regressor__n_estimators': 479, 'rf_regressor__max_depth': 19, 'rf_regressor__min_samples_split': 6, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 'sqrt'}. Best is trial 8 with value: 0.8875246056110265.\n",
            "[I 2025-07-31 14:16:25,052] Trial 13 finished with value: 0.8830709198770943 and parameters: {'rf_regressor__n_estimators': 405, 'rf_regressor__max_depth': 14, 'rf_regressor__min_samples_split': 2, 'rf_regressor__min_samples_leaf': 4, 'rf_regressor__max_features': 1.0}. Best is trial 8 with value: 0.8875246056110265.\n",
            "[I 2025-07-31 14:16:42,833] Trial 14 finished with value: 0.8879426909055721 and parameters: {'rf_regressor__n_estimators': 314, 'rf_regressor__max_depth': 14, 'rf_regressor__min_samples_split': 6, 'rf_regressor__min_samples_leaf': 3, 'rf_regressor__max_features': 0.6}. Best is trial 14 with value: 0.8879426909055721.\n",
            "[I 2025-07-31 14:16:50,554] Trial 15 finished with value: 0.8870463577921237 and parameters: {'rf_regressor__n_estimators': 118, 'rf_regressor__max_depth': 19, 'rf_regressor__min_samples_split': 7, 'rf_regressor__min_samples_leaf': 3, 'rf_regressor__max_features': 0.6}. Best is trial 14 with value: 0.8879426909055721.\n",
            "[I 2025-07-31 14:17:21,382] Trial 16 finished with value: 0.8889424760575728 and parameters: {'rf_regressor__n_estimators': 461, 'rf_regressor__max_depth': 25, 'rf_regressor__min_samples_split': 6, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.6}. Best is trial 16 with value: 0.8889424760575728.\n",
            "[I 2025-07-31 14:17:51,135] Trial 17 finished with value: 0.888107958422089 and parameters: {'rf_regressor__n_estimators': 497, 'rf_regressor__max_depth': 15, 'rf_regressor__min_samples_split': 8, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.6}. Best is trial 16 with value: 0.8889424760575728.\n",
            "[I 2025-07-31 14:18:23,446] Trial 18 finished with value: 0.8889230454107898 and parameters: {'rf_regressor__n_estimators': 500, 'rf_regressor__max_depth': 21, 'rf_regressor__min_samples_split': 8, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.6}. Best is trial 16 with value: 0.8889424760575728.\n",
            "[I 2025-07-31 14:18:41,832] Trial 19 finished with value: 0.871923191001866 and parameters: {'rf_regressor__n_estimators': 419, 'rf_regressor__max_depth': 21, 'rf_regressor__min_samples_split': 8, 'rf_regressor__min_samples_leaf': 10, 'rf_regressor__max_features': 0.6}. Best is trial 16 with value: 0.8889424760575728.\n",
            "[I 2025-07-31 14:18:54,173] Trial 20 finished with value: 0.865179628647932 and parameters: {'rf_regressor__n_estimators': 448, 'rf_regressor__max_depth': 25, 'rf_regressor__min_samples_split': 10, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 'sqrt'}. Best is trial 16 with value: 0.8889424760575728.\n",
            "[I 2025-07-31 14:19:04,666] Trial 21 finished with value: 0.8262374628848177 and parameters: {'rf_regressor__n_estimators': 450, 'rf_regressor__max_depth': 22, 'rf_regressor__min_samples_split': 5, 'rf_regressor__min_samples_leaf': 4, 'rf_regressor__max_features': 'log2'}. Best is trial 16 with value: 0.8889424760575728.\n",
            "[I 2025-07-31 14:19:28,157] Trial 22 finished with value: 0.8860427489614106 and parameters: {'rf_regressor__n_estimators': 402, 'rf_regressor__max_depth': 20, 'rf_regressor__min_samples_split': 9, 'rf_regressor__min_samples_leaf': 3, 'rf_regressor__max_features': 0.6}. Best is trial 16 with value: 0.8889424760575728.\n",
            "[I 2025-07-31 14:20:00,071] Trial 23 finished with value: 0.8897567606384359 and parameters: {'rf_regressor__n_estimators': 471, 'rf_regressor__max_depth': 17, 'rf_regressor__min_samples_split': 5, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.6}. Best is trial 23 with value: 0.8897567606384359.\n",
            "[I 2025-07-31 14:20:35,203] Trial 24 finished with value: 0.8901478222330018 and parameters: {'rf_regressor__n_estimators': 499, 'rf_regressor__max_depth': 18, 'rf_regressor__min_samples_split': 5, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.6}. Best is trial 24 with value: 0.8901478222330018.\n",
            "[I 2025-07-31 14:21:05,306] Trial 25 finished with value: 0.8901320964357251 and parameters: {'rf_regressor__n_estimators': 452, 'rf_regressor__max_depth': 17, 'rf_regressor__min_samples_split': 4, 'rf_regressor__min_samples_leaf': 2, 'rf_regressor__max_features': 0.6}. Best is trial 24 with value: 0.8901478222330018.\n",
            "[I 2025-07-31 14:21:32,778] Trial 26 finished with value: 0.890169731061425 and parameters: {'rf_regressor__n_estimators': 411, 'rf_regressor__max_depth': 17, 'rf_regressor__min_samples_split': 4, 'rf_regressor__min_samples_leaf': 2, 'rf_regressor__max_features': 0.6}. Best is trial 26 with value: 0.890169731061425.\n",
            "[I 2025-07-31 14:21:58,254] Trial 27 finished with value: 0.8901284439065573 and parameters: {'rf_regressor__n_estimators': 378, 'rf_regressor__max_depth': 17, 'rf_regressor__min_samples_split': 4, 'rf_regressor__min_samples_leaf': 2, 'rf_regressor__max_features': 0.6}. Best is trial 26 with value: 0.890169731061425.\n",
            "[I 2025-07-31 14:22:09,385] Trial 28 finished with value: 0.8542893816714228 and parameters: {'rf_regressor__n_estimators': 427, 'rf_regressor__max_depth': 16, 'rf_regressor__min_samples_split': 4, 'rf_regressor__min_samples_leaf': 3, 'rf_regressor__max_features': 'sqrt'}. Best is trial 26 with value: 0.890169731061425.\n",
            "[I 2025-07-31 14:22:17,891] Trial 29 finished with value: 0.8200079201271704 and parameters: {'rf_regressor__n_estimators': 388, 'rf_regressor__max_depth': 18, 'rf_regressor__min_samples_split': 4, 'rf_regressor__min_samples_leaf': 5, 'rf_regressor__max_features': 'log2'}. Best is trial 26 with value: 0.890169731061425.\n",
            "[I 2025-07-31 14:22:38,294] Trial 30 finished with value: 0.8791443754056293 and parameters: {'rf_regressor__n_estimators': 430, 'rf_regressor__max_depth': 13, 'rf_regressor__min_samples_split': 20, 'rf_regressor__min_samples_leaf': 2, 'rf_regressor__max_features': 0.6}. Best is trial 26 with value: 0.890169731061425.\n",
            "[I 2025-07-31 14:22:57,805] Trial 31 finished with value: 0.8858320104121181 and parameters: {'rf_regressor__n_estimators': 355, 'rf_regressor__max_depth': 13, 'rf_regressor__min_samples_split': 2, 'rf_regressor__min_samples_leaf': 4, 'rf_regressor__max_features': 0.6}. Best is trial 26 with value: 0.890169731061425.\n",
            "[I 2025-07-31 14:23:19,824] Trial 32 finished with value: 0.8777185666178514 and parameters: {'rf_regressor__n_estimators': 445, 'rf_regressor__max_depth': 16, 'rf_regressor__min_samples_split': 17, 'rf_regressor__min_samples_leaf': 6, 'rf_regressor__max_features': 0.6}. Best is trial 26 with value: 0.890169731061425.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Optuna Results for RandomForestRegressor ---\n",
            "Number of finished trials: 33\n",
            "Best trial:\n",
            "  Value (R2): 0.8902\n",
            "  Params: \n",
            "    rf_regressor__n_estimators: 411\n",
            "    rf_regressor__max_depth: 17\n",
            "    rf_regressor__min_samples_split: 4\n",
            "    rf_regressor__min_samples_leaf: 2\n",
            "    rf_regressor__max_features: 0.6\n",
            "\n",
            "Fitting final RandomForestRegressor pipeline on the entire training dataset...\n",
            "\n",
            "--- Final RandomForestRegressor CV Metrics (using Optuna's best params) ---\n",
            "CV R2:\t\t 0.8902\n",
            "CV MAE:\t\t 12969.9524\n",
            "CV MAPE:\t 0.1052\n",
            "CV MSE:\t\t 636764156.5493\n",
            "\n",
            "--- Final RandomForestRegressor Test Set Metrics ---\n",
            "Test R2:\t\t 0.9257\n",
            "Test MAE:\t\t 11635.5562\n"
          ]
        }
      ],
      "source": [
        "def objective_rf(trial):\n",
        "    # Hyperparameters for RandomForestRegressor\n",
        "    n_estimators = trial.suggest_int(\"rf_regressor__n_estimators\", 50, 500) # Number of trees\n",
        "    max_depth = trial.suggest_int(\"rf_regressor__max_depth\", 5, 25) # Max depth of trees\n",
        "    min_samples_split = trial.suggest_int(\"rf_regressor__min_samples_split\", 2, 20) # Min samples to split\n",
        "    min_samples_leaf = trial.suggest_int(\"rf_regressor__min_samples_leaf\", 1, 10) # Min samples per leaf\n",
        "    # max_features is crucial for Random Forests to reduce correlation between trees\n",
        "    max_features = trial.suggest_categorical(\"rf_regressor__max_features\", ['sqrt', 'log2', 0.6, 0.8, 1.0])\n",
        "\n",
        "    # Determine numeric and categorical features within the function, based on X_train\n",
        "    numeric_features_local = X_train.select_dtypes([np.number]).columns.tolist()\n",
        "    categorical_features_local = X_train.dtypes[X_train.dtypes == \"object\"].index.tolist()\n",
        "\n",
        "    # ColumnTransformer setup\n",
        "    column_transformer = ColumnTransformer([\n",
        "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features_local),\n",
        "        ('scaler', MinMaxScaler(), numeric_features_local) # Include MinMaxScaler\n",
        "    ], remainder='passthrough')\n",
        "\n",
        "    # Create the pipeline with chosen hyperparameters\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessing', column_transformer),\n",
        "        ('rf_regressor', RandomForestRegressor( # Changed to RandomForestRegressor\n",
        "            random_state=42,\n",
        "            n_jobs=-1, # Use all available CPU cores for faster training\n",
        "            n_estimators=n_estimators,\n",
        "            max_depth=max_depth,\n",
        "            min_samples_split=min_samples_split,\n",
        "            min_samples_leaf=min_samples_leaf,\n",
        "            max_features=max_features\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    # Evaluate with cross-validation\n",
        "    y_pred_cv = cross_val_predict(pipeline, X_train, y_train, cv=5, n_jobs=-1)\n",
        "\n",
        "    r2 = r2_score(y_train, y_pred_cv)\n",
        "    return r2\n",
        "\n",
        "# --- Optuna Study Setup and Run ---\n",
        "study_rf = optuna.create_study(\n",
        "    storage=\"sqlite:///rf_optuna_study.db\", # Changed database name\n",
        "    study_name=\"random_forest_hyperparameter_tuning\", # Changed study name\n",
        "    direction=\"maximize\",\n",
        "    load_if_exists=True,\n",
        "    sampler=TPESampler(seed=42,),\n",
        "    pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
        ")\n",
        "\n",
        "print(\"Starting Optuna optimization for RandomForestRegressor...\")\n",
        "study_rf.optimize(objective_rf, n_trials=100, timeout=600)\n",
        "\n",
        "# --- 4. Get Best Results ---\n",
        "print(\"\\n--- Optuna Results for RandomForestRegressor ---\")\n",
        "print(f\"Number of finished trials: {len(study_rf.trials)}\")\n",
        "print(f\"Best trial:\")\n",
        "print(f\"  Value (R2): {study_rf.best_value:.4f}\")\n",
        "print(\"  Params: \")\n",
        "for key, value in study_rf.best_params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "# --- 5. Train Final Model with Best Parameters ---\n",
        "best_params_rf = study_rf.best_params\n",
        "\n",
        "# Extract parameters for RandomForestRegressor from Optuna's best_params\n",
        "# Note the prefix 'rf_regressor__'\n",
        "rf_params = {k.replace('rf_regressor__', ''): v for k, v in best_params_rf.items()}\n",
        "\n",
        "# Create ColumnTransformer (same as in objective)\n",
        "# Determine numeric and categorical features based on the full training data before the split for the final model\n",
        "numeric_features_final = X.select_dtypes([np.number]).columns.tolist()\n",
        "categorical_features_final = X.dtypes[X.dtypes == \"object\"].index.tolist()\n",
        "\n",
        "final_column_transformer = ColumnTransformer([\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features_final),\n",
        "    ('scaler', MinMaxScaler(), numeric_features_final)\n",
        "], remainder='passthrough')\n",
        "\n",
        "# Create final pipeline\n",
        "final_pipeline_rf = Pipeline([\n",
        "    ('preprocessing', final_column_transformer),\n",
        "    ('rf_regressor', RandomForestRegressor(\n",
        "        random_state=42,\n",
        "        n_jobs=-1, # Use all available CPU cores for final model too\n",
        "        **rf_params # Unpack the best parameters\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Fit the final model on the entire training dataset\n",
        "print(\"\\nFitting final RandomForestRegressor pipeline on the entire training dataset...\")\n",
        "final_pipeline_rf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the final model on the training set with cross-validation\n",
        "y_pred_train_final_rf = cross_val_predict(final_pipeline_rf, X_train, y_train, cv=5, n_jobs=-1)\n",
        "\n",
        "print(\"\\n--- Final RandomForestRegressor CV Metrics (using Optuna's best params) ---\")\n",
        "print(\"CV R2:\\t\\t %.4f\" % r2_score(y_train, y_pred_train_final_rf))\n",
        "print(\"CV MAE:\\t\\t %.4f\" % mean_absolute_error(y_train, y_pred_train_final_rf))\n",
        "print(\"CV MAPE:\\t %.4f\" % mean_absolute_percentage_error(y_train, y_pred_train_final_rf))\n",
        "print(\"CV MSE:\\t\\t %.4f\" % mean_squared_error(y_train, y_pred_train_final_rf))\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_pred_test_final_rf = final_pipeline_rf.predict(X_test)\n",
        "print(\"\\n--- Final RandomForestRegressor Test Set Metrics ---\")\n",
        "print(\"Test R2:\\t\\t %.4f\" % r2_score(y_test, y_pred_test_final_rf))\n",
        "print(\"Test MAE:\\t\\t %.4f\" % mean_absolute_error(y_test, y_pred_test_final_rf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTgWbnK-5Ase"
      },
      "outputs": [],
      "source": [
        "rf_optuna = final_pipeline_rf.predict(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LikEWgM25DF5"
      },
      "outputs": [],
      "source": [
        "submission_df = pd.DataFrame({\n",
        "    'id': test_id_column,\n",
        "    'predicted_price': rf_optuna\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK1b29ib4ymJ"
      },
      "outputs": [],
      "source": [
        "submission_df.to_csv('dt_rfr.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFvyPlR06Ew3",
        "outputId": "33add08a-d36f-47a9-e4eb-c4ec890e498c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-31 15:40:44,059] Using an existing study with name 'random_forest_mape_tuning' instead of creating a new one.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Optuna optimization for RandomForestRegressor, focusing on MINIMIZING MAPE...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-07-31 15:41:41,763] Trial 95 finished with value: 0.10381407390187342 and parameters: {'rf_regressor__n_estimators': 438, 'rf_regressor__max_depth': 25, 'rf_regressor__min_samples_split': 3, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.8}. Best is trial 93 with value: 0.10375905711017382.\n",
            "[I 2025-07-31 15:42:25,478] Trial 96 finished with value: 0.10383459613119751 and parameters: {'rf_regressor__n_estimators': 442, 'rf_regressor__max_depth': 25, 'rf_regressor__min_samples_split': 3, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.8}. Best is trial 93 with value: 0.10375905711017382.\n",
            "[I 2025-07-31 15:42:59,833] Trial 97 finished with value: 0.10772128690070945 and parameters: {'rf_regressor__n_estimators': 439, 'rf_regressor__max_depth': 25, 'rf_regressor__min_samples_split': 10, 'rf_regressor__min_samples_leaf': 2, 'rf_regressor__max_features': 0.8}. Best is trial 93 with value: 0.10375905711017382.\n",
            "[I 2025-07-31 15:43:42,763] Trial 98 finished with value: 0.10415082761900286 and parameters: {'rf_regressor__n_estimators': 466, 'rf_regressor__max_depth': 25, 'rf_regressor__min_samples_split': 4, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.8}. Best is trial 93 with value: 0.10375905711017382.\n",
            "[I 2025-07-31 15:44:17,561] Trial 99 finished with value: 0.10462628028143599 and parameters: {'rf_regressor__n_estimators': 387, 'rf_regressor__max_depth': 23, 'rf_regressor__min_samples_split': 5, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.8}. Best is trial 93 with value: 0.10375905711017382.\n",
            "[I 2025-07-31 15:44:53,632] Trial 100 finished with value: 0.1047412066609453 and parameters: {'rf_regressor__n_estimators': 429, 'rf_regressor__max_depth': 25, 'rf_regressor__min_samples_split': 3, 'rf_regressor__min_samples_leaf': 2, 'rf_regressor__max_features': 0.8}. Best is trial 93 with value: 0.10375905711017382.\n",
            "[I 2025-07-31 15:45:09,735] Trial 101 finished with value: 0.12031032692784317 and parameters: {'rf_regressor__n_estimators': 500, 'rf_regressor__max_depth': 23, 'rf_regressor__min_samples_split': 4, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 'log2'}. Best is trial 93 with value: 0.10375905711017382.\n",
            "[I 2025-07-31 15:45:50,059] Trial 102 finished with value: 0.10382978506311387 and parameters: {'rf_regressor__n_estimators': 405, 'rf_regressor__max_depth': 24, 'rf_regressor__min_samples_split': 3, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.8}. Best is trial 93 with value: 0.10375905711017382.\n",
            "[I 2025-07-31 15:46:30,259] Trial 103 finished with value: 0.10382978506311387 and parameters: {'rf_regressor__n_estimators': 405, 'rf_regressor__max_depth': 24, 'rf_regressor__min_samples_split': 3, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.8}. Best is trial 93 with value: 0.10375905711017382.\n",
            "[I 2025-07-31 15:47:09,859] Trial 104 finished with value: 0.10384628844966516 and parameters: {'rf_regressor__n_estimators': 399, 'rf_regressor__max_depth': 25, 'rf_regressor__min_samples_split': 3, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.8}. Best is trial 93 with value: 0.10375905711017382.\n",
            "[I 2025-07-31 15:47:50,558] Trial 105 finished with value: 0.10384664985590031 and parameters: {'rf_regressor__n_estimators': 404, 'rf_regressor__max_depth': 25, 'rf_regressor__min_samples_split': 3, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.8}. Best is trial 93 with value: 0.10375905711017382.\n",
            "[I 2025-07-31 15:48:24,804] Trial 106 finished with value: 0.10471167417953774 and parameters: {'rf_regressor__n_estimators': 408, 'rf_regressor__max_depth': 25, 'rf_regressor__min_samples_split': 3, 'rf_regressor__min_samples_leaf': 2, 'rf_regressor__max_features': 0.8}. Best is trial 93 with value: 0.10375905711017382.\n",
            "[I 2025-07-31 15:48:59,939] Trial 107 finished with value: 0.10421922232364207 and parameters: {'rf_regressor__n_estimators': 386, 'rf_regressor__max_depth': 25, 'rf_regressor__min_samples_split': 4, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.8}. Best is trial 93 with value: 0.10375905711017382.\n",
            "[I 2025-07-31 15:49:32,138] Trial 108 finished with value: 0.1036077476655072 and parameters: {'rf_regressor__n_estimators': 394, 'rf_regressor__max_depth': 25, 'rf_regressor__min_samples_split': 3, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.6}. Best is trial 108 with value: 0.1036077476655072.\n",
            "[I 2025-07-31 15:49:53,458] Trial 109 finished with value: 0.10973584205821461 and parameters: {'rf_regressor__n_estimators': 395, 'rf_regressor__max_depth': 25, 'rf_regressor__min_samples_split': 14, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.6}. Best is trial 108 with value: 0.1036077476655072.\n",
            "[I 2025-07-31 15:50:17,313] Trial 110 finished with value: 0.10535001570769913 and parameters: {'rf_regressor__n_estimators': 359, 'rf_regressor__max_depth': 25, 'rf_regressor__min_samples_split': 5, 'rf_regressor__min_samples_leaf': 2, 'rf_regressor__max_features': 0.6}. Best is trial 108 with value: 0.1036077476655072.\n",
            "[I 2025-07-31 15:50:51,363] Trial 111 finished with value: 0.10359253996227243 and parameters: {'rf_regressor__n_estimators': 426, 'rf_regressor__max_depth': 24, 'rf_regressor__min_samples_split': 3, 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__max_features': 0.6}. Best is trial 111 with value: 0.10359253996227243.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Optuna Results for RandomForestRegressor (MAPE Optimization) ---\n",
            "Number of finished trials: 112\n",
            "Best trial:\n",
            "  Value (MAPE): 0.1036\n",
            "  Params: \n",
            "    rf_regressor__n_estimators: 426\n",
            "    rf_regressor__max_depth: 24\n",
            "    rf_regressor__min_samples_split: 3\n",
            "    rf_regressor__min_samples_leaf: 1\n",
            "    rf_regressor__max_features: 0.6\n",
            "\n",
            "Fitting final RandomForestRegressor pipeline (MAPE optimized) on the entire training dataset...\n",
            "\n",
            "--- Final RandomForestRegressor CV Metrics (MAPE Optimized) ---\n",
            "CV R2:\t\t 0.8908\n",
            "CV MAE:\t\t 12778.3328\n",
            "CV MAPE:\t 0.1036\n",
            "CV MSE:\t\t 633103199.1219\n",
            "\n",
            "--- Final RandomForestRegressor Test Set Metrics (MAPE Optimized) ---\n",
            "Test R2:\t\t 0.9261\n",
            "Test MAE:\t\t 11480.8509\n",
            "Test MAPE:\t\t 0.0965\n",
            "Test MSE:\t\t 419305005.8861\n"
          ]
        }
      ],
      "source": [
        "def objective_rf_mape(trial):\n",
        "    n_estimators = trial.suggest_int(\"rf_regressor__n_estimators\", 50, 500)\n",
        "    max_depth = trial.suggest_int(\"rf_regressor__max_depth\", 5, 25)\n",
        "    min_samples_split = trial.suggest_int(\"rf_regressor__min_samples_split\", 2, 20)\n",
        "    min_samples_leaf = trial.suggest_int(\"rf_regressor__min_samples_leaf\", 1, 10)\n",
        "    max_features = trial.suggest_categorical(\"rf_regressor__max_features\", ['sqrt', 'log2', 0.6, 0.8, 1.0])\n",
        "\n",
        "    # Determine numeric and categorical features within the function, based on X_train\n",
        "    numeric_features_local_trial = X_train.select_dtypes([np.number]).columns.tolist()\n",
        "    categorical_features_local_trial = X_train.dtypes[X_train.dtypes == \"object\"].index.tolist()\n",
        "\n",
        "    column_transformer = ColumnTransformer([\n",
        "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features_local_trial),\n",
        "        ('scaler', MinMaxScaler(), numeric_features_local_trial)\n",
        "    ], remainder='passthrough')\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessing', column_transformer),\n",
        "        ('rf_regressor', RandomForestRegressor(\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            n_estimators=n_estimators,\n",
        "            max_depth=max_depth,\n",
        "            min_samples_split=min_samples_split,\n",
        "            min_samples_leaf=min_samples_leaf,\n",
        "            max_features=max_features\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    y_pred_cv = cross_val_predict(pipeline, X_train, y_train, cv=5, n_jobs=-1)\n",
        "\n",
        "    # Calculate MAPE. Ensure y_train does not have zeros.\n",
        "    # The y_train passed to cross_val_predict (and thus here) already has epsilon added if needed.\n",
        "    mape = mean_absolute_percentage_error(y_train, y_pred_cv)\n",
        "    return mape # Optuna will MINIMIZE this value\n",
        "\n",
        "\n",
        "# --- Optuna Study Setup and Run (Optimizing for MAPE) ---\n",
        "study_rf_mape = optuna.create_study(\n",
        "    storage=\"sqlite:///rf_optuna_mape_study.db\", # New database name for MAPE optimization\n",
        "    study_name=\"random_forest_mape_tuning\", # New study name\n",
        "    direction=\"minimize\", # <--- CRITICAL CHANGE: Minimize MAPE\n",
        "    load_if_exists=True,\n",
        "    sampler=TPESampler(seed=42,),\n",
        "    pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=10)\n",
        ")\n",
        "\n",
        "print(\"Starting Optuna optimization for RandomForestRegressor, focusing on MINIMIZING MAPE...\")\n",
        "study_rf_mape.optimize(objective_rf_mape, n_trials=100, timeout=600)\n",
        "\n",
        "# --- 4. Get Best Results ---\n",
        "print(\"\\n--- Optuna Results for RandomForestRegressor (MAPE Optimization) ---\")\n",
        "print(f\"Number of finished trials: {len(study_rf_mape.trials)}\")\n",
        "print(f\"Best trial:\")\n",
        "# Optuna returns the optimized metric value, which is MAPE in this case\n",
        "print(f\"  Value (MAPE): {study_rf_mape.best_value:.4f}\")\n",
        "print(\"  Params: \")\n",
        "for key, value in study_rf_mape.best_params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "# --- 5. Train Final Model with Best Parameters ---\n",
        "best_params_rf_mape = study_rf_mape.best_params\n",
        "\n",
        "rf_params_mape = {k.replace('rf_regressor__', ''): v for k, v in best_params_rf_mape.items()}\n",
        "\n",
        "# Define features for the final pipeline\n",
        "numeric_features_final = X_train.select_dtypes([np.number]).columns.tolist()\n",
        "categorical_features_final = X_train.dtypes[X_train.dtypes == \"object\"].index.tolist()\n",
        "\n",
        "\n",
        "final_column_transformer_mape = ColumnTransformer([\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features_final),\n",
        "    ('scaler', MinMaxScaler(), numeric_features_final)\n",
        "], remainder='passthrough')\n",
        "\n",
        "final_pipeline_rf_mape = Pipeline([\n",
        "    ('preprocessing', final_column_transformer_mape),\n",
        "    ('rf_regressor', RandomForestRegressor(\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        **rf_params_mape\n",
        "    ))\n",
        "])\n",
        "\n",
        "print(\"\\nFitting final RandomForestRegressor pipeline (MAPE optimized) on the entire training dataset...\")\n",
        "final_pipeline_rf_mape.fit(X_train, y_train) # Fit using the y_train that was used for Optuna (potentially adjusted for MAPE)\n",
        "\n",
        "# --- Evaluate with cross-validation on Training Set ---\n",
        "y_pred_train_final_rf_mape = cross_val_predict(final_pipeline_rf_mape, X_train, y_train, cv=5, n_jobs=-1)\n",
        "\n",
        "print(\"\\n--- Final RandomForestRegressor CV Metrics (MAPE Optimized) ---\")\n",
        "print(\"CV R2:\\t\\t %.4f\" % r2_score(y_train, y_pred_train_final_rf_mape))\n",
        "print(\"CV MAE:\\t\\t %.4f\" % mean_absolute_error(y_train, y_pred_train_final_rf_mape))\n",
        "print(\"CV MAPE:\\t %.4f\" % mean_absolute_percentage_error(y_train, y_pred_train_final_rf_mape)) # Optimized metric\n",
        "print(\"CV MSE:\\t\\t %.4f\" % mean_squared_error(y_train, y_pred_train_final_rf_mape))\n",
        "\n",
        "# --- Evaluate on the Test Set ---\n",
        "y_pred_test_final_rf_mape = final_pipeline_rf_mape.predict(X_test)\n",
        "print(\"\\n--- Final RandomForestRegressor Test Set Metrics (MAPE Optimized) ---\")\n",
        "print(\"Test R2:\\t\\t %.4f\" % r2_score(y_test, y_pred_test_final_rf_mape))\n",
        "print(\"Test MAE:\\t\\t %.4f\" % mean_absolute_error(y_test, y_pred_test_final_rf_mape))\n",
        "print(\"Test MAPE:\\t\\t %.4f\" % mean_absolute_percentage_error(y_test, y_pred_test_final_rf_mape)) # Optimized metric\n",
        "print(\"Test MSE:\\t\\t %.4f\" % mean_squared_error(y_test, y_pred_test_final_rf_mape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRENeLDZIYEP"
      },
      "outputs": [],
      "source": [
        "rf_optunam = final_pipeline_rf_mape.predict(test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4E7bOneIXtK"
      },
      "outputs": [],
      "source": [
        "submission_df = pd.DataFrame({\n",
        "    'id': test_id_column,\n",
        "    'predicted_price': rf_optunam\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nJq-6RJIXYD"
      },
      "outputs": [],
      "source": [
        "submission_df.to_csv('dt_rfr1.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "authorship_tag": "ABX9TyNGGX6uR7km764C/zteXuaF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}